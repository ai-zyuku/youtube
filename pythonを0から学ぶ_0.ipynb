{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\s180168\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer#サンプルデータセットのライブラリ\n",
    "import pandas as pd#テーブルデータや時系列データを操作するためのデータ構造と演算のライブラリ\n",
    "\n",
    "data = load_breast_cancer()#データ読み込み\n",
    "data#dataを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的変数と説明変数のテーブルデータに変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.DataFrame(data=data.data,columns=data.feature_names)#説明変数のテーブルデータに変換。データ:data,カラム:columns\n",
    "train_x.head()#train_xのデータフレームの最初の5行表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = pd.DataFrame(data=data.target,columns=['class'])#目的変数のテーブルデータに変換。データ:data,カラム:columns\n",
    "train_y.head()#train_yのデータフレームの最初の5行表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score#混同行列を計算するライブラリ\n",
    "from sklearn.model_selection import KFold#ホールドアウト、交差検証(cross validation)するライブラリ\n",
    "import lightgbm as lgb#LightGBMのライブラリ\n",
    "import numpy as np#数値計算するライブラリ\n",
    "\n",
    "# 各foldのスコアを保存する空のリスト\n",
    "scores_accuracy = []#[]:正解率用のリスト\n",
    "scores_logloss = []#[]:評価関数LogLoss用のリスト\n",
    "\n",
    "# クロスバリデーション(k-fold cross validation)を行う\n",
    "# 学習データを4つに分割し、うち1つをバリデーションデータとすることを、バリデーションデータを変えて繰り返す\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)#n_splits:分割,shuffle:シャッフルするかどうか,random_state:何度実行しても同じランダムな分割になるように固定する値。指定しないと毎回分割データが変わり結果が異なってしまう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認用【for tr_idx, va_idx in kf.split(train_x):】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########1回目:データ数 tr:379,va:190########\n",
      "tr_idx:[  1   3   4   5   8  12  13  14  16  17  20  21  23  24  25  26  27  28\n",
      "  31  32  34  35  36  37  38  40  41  42  43  44  45  47  48  49  50  51\n",
      "  52  53  56  57  58  59  61  62  64  65  66  67  71  74  80  85  87  91\n",
      "  92  94  95  96  97  98  99 100 102 103 105 106 107 111 112 113 115 116\n",
      " 119 120 121 122 123 125 126 127 128 129 130 133 134 135 136 138 139 142\n",
      " 143 146 147 150 151 152 154 156 157 159 160 161 162 164 166 168 169 170\n",
      " 171 173 174 175 178 179 180 183 186 187 189 190 191 193 194 197 198 200\n",
      " 201 202 205 206 207 212 213 214 215 216 217 218 219 220 221 223 224 225\n",
      " 226 229 230 232 233 234 236 237 239 240 241 242 243 246 251 252 253 254\n",
      " 256 258 259 260 262 263 266 267 268 269 270 272 273 276 277 278 279 280\n",
      " 282 283 285 286 288 289 291 292 293 294 295 296 297 299 300 301 302 303\n",
      " 304 306 307 308 309 311 312 313 314 315 316 317 318 319 321 323 324 325\n",
      " 326 327 328 330 335 336 337 338 339 340 342 343 344 345 346 347 348 349\n",
      " 350 351 352 354 356 357 358 359 360 361 363 365 366 367 368 370 371 372\n",
      " 373 374 375 376 377 378 379 381 383 385 386 387 388 389 391 392 397 398\n",
      " 400 401 403 405 406 409 412 413 415 416 417 418 419 420 423 427 429 430\n",
      " 432 433 435 436 437 438 439 440 443 444 445 447 448 450 451 452 454 455\n",
      " 456 458 459 460 461 463 465 466 467 469 471 472 473 474 475 476 478 479\n",
      " 480 481 483 484 485 487 488 489 490 491 492 493 494 495 496 497 499 502\n",
      " 504 505 506 507 508 509 510 513 514 515 516 518 519 521 522 524 525 529\n",
      " 533 534 536 537 539 543 544 546 547 548 550 552 553 554 558 559 560 563\n",
      " 566]\n",
      "va_idx:[  0   2   6   7   9  10  11  15  18  19  22  29  30  33  39  46  54  55\n",
      "  60  63  68  69  70  72  73  75  76  77  78  79  81  82  83  84  86  88\n",
      "  89  90  93 101 104 108 109 110 114 117 118 124 131 132 137 140 141 144\n",
      " 145 148 149 153 155 158 163 165 167 172 176 177 181 182 184 185 188 192\n",
      " 195 196 199 203 204 208 209 210 211 222 227 228 231 235 238 244 245 247\n",
      " 248 249 250 255 257 261 264 265 271 274 275 281 284 287 290 298 305 310\n",
      " 320 322 329 331 332 333 334 341 353 355 362 364 369 380 382 384 390 393\n",
      " 394 395 396 399 402 404 407 408 410 411 414 421 422 424 425 426 428 431\n",
      " 434 441 442 446 449 453 457 462 464 468 470 477 482 486 498 500 501 503\n",
      " 511 512 517 520 523 526 527 528 530 531 532 535 538 540 541 542 545 549\n",
      " 551 555 556 557 561 562 564 565 567 568]\n",
      "########2回目:データ数 tr:379,va:190########\n",
      "tr_idx:[  0   1   2   4   6   7   8   9  10  11  12  13  14  15  18  19  20  21\n",
      "  22  27  28  29  30  32  33  34  35  39  40  41  43  44  46  47  51  52\n",
      "  54  55  58  60  61  62  63  64  65  68  69  70  71  72  73  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  93  95  98  99\n",
      " 100 101 102 104 105 106 107 108 109 110 114 117 118 120 121 124 127 128\n",
      " 130 131 132 133 134 135 137 138 140 141 142 144 145 148 149 153 155 156\n",
      " 158 159 160 161 162 163 165 166 167 169 170 171 172 176 177 178 181 182\n",
      " 184 185 186 187 188 189 190 191 192 195 196 199 200 201 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 221 222 224 226 227 228 230\n",
      " 231 235 236 238 240 241 242 243 244 245 247 248 249 250 251 252 254 255\n",
      " 256 257 259 260 261 264 265 267 269 270 271 273 274 275 276 279 281 282\n",
      " 283 284 285 287 288 290 292 295 298 300 303 305 308 309 310 313 315 320\n",
      " 322 326 327 329 330 331 332 333 334 337 339 341 343 344 345 347 350 351\n",
      " 353 355 358 359 362 364 366 369 372 376 378 379 380 382 384 385 387 389\n",
      " 390 391 392 393 394 395 396 397 399 400 401 402 404 406 407 408 409 410\n",
      " 411 412 413 414 417 418 419 421 422 424 425 426 427 428 429 430 431 434\n",
      " 435 441 442 445 446 447 448 449 453 454 455 456 457 458 459 461 462 464\n",
      " 466 467 468 470 472 474 475 476 477 478 479 482 483 484 486 488 491 492\n",
      " 493 498 500 501 503 504 505 506 508 509 510 511 512 515 516 517 518 520\n",
      " 522 523 524 525 526 527 528 529 530 531 532 534 535 537 538 540 541 542\n",
      " 545 549 551 552 554 555 556 557 558 559 560 561 562 563 564 565 566 567\n",
      " 568]\n",
      "va_idx:[  3   5  16  17  23  24  25  26  31  36  37  38  42  45  48  49  50  53\n",
      "  56  57  59  66  67  74  92  94  96  97 103 111 112 113 115 116 119 122\n",
      " 123 125 126 129 136 139 143 146 147 150 151 152 154 157 164 168 173 174\n",
      " 175 179 180 183 193 194 197 198 202 218 219 220 223 225 229 232 233 234\n",
      " 237 239 246 253 258 262 263 266 268 272 277 278 280 286 289 291 293 294\n",
      " 296 297 299 301 302 304 306 307 311 312 314 316 317 318 319 321 323 324\n",
      " 325 328 335 336 338 340 342 346 348 349 352 354 356 357 360 361 363 365\n",
      " 367 368 370 371 373 374 375 377 381 383 386 388 398 403 405 415 416 420\n",
      " 423 432 433 436 437 438 439 440 443 444 450 451 452 460 463 465 469 471\n",
      " 473 480 481 485 487 489 490 494 495 496 497 499 502 507 513 514 519 521\n",
      " 533 536 539 543 544 546 547 548 550 553]\n",
      "########3回目:データ数 tr:380,va:189########\n",
      "tr_idx:[  0   2   3   5   6   7   9  10  11  15  16  17  18  19  22  23  24  25\n",
      "  26  29  30  31  33  36  37  38  39  42  45  46  48  49  50  53  54  55\n",
      "  56  57  59  60  63  66  67  68  69  70  72  73  74  75  76  77  78  79\n",
      "  81  82  83  84  86  88  89  90  92  93  94  96  97 101 103 104 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 122 123 124 125 126 129 131 132\n",
      " 136 137 139 140 141 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 157 158 163 164 165 167 168 172 173 174 175 176 177 179 180 181 182 183\n",
      " 184 185 188 192 193 194 195 196 197 198 199 202 203 204 208 209 210 211\n",
      " 218 219 220 222 223 225 227 228 229 231 232 233 234 235 237 238 239 244\n",
      " 245 246 247 248 249 250 253 255 257 258 261 262 263 264 265 266 268 271\n",
      " 272 274 275 277 278 280 281 284 286 287 289 290 291 293 294 296 297 298\n",
      " 299 301 302 304 305 306 307 310 311 312 314 316 317 318 319 320 321 322\n",
      " 323 324 325 328 329 331 332 333 334 335 336 338 340 341 342 346 348 349\n",
      " 352 353 354 355 356 357 360 361 362 363 364 365 367 368 369 370 371 373\n",
      " 374 375 377 380 381 382 383 384 386 388 390 393 394 395 396 398 399 402\n",
      " 403 404 405 407 408 410 411 414 415 416 420 421 422 423 424 425 426 428\n",
      " 431 432 433 434 436 437 438 439 440 441 442 443 444 446 449 450 451 452\n",
      " 453 457 460 462 463 464 465 468 469 470 471 473 477 480 481 482 485 486\n",
      " 487 489 490 494 495 496 497 498 499 500 501 502 503 507 511 512 513 514\n",
      " 517 519 520 521 523 526 527 528 530 531 532 533 535 536 538 539 540 541\n",
      " 542 543 544 545 546 547 548 549 550 551 553 555 556 557 561 562 564 565\n",
      " 567 568]\n",
      "va_idx:[  1   4   8  12  13  14  20  21  27  28  32  34  35  40  41  43  44  47\n",
      "  51  52  58  61  62  64  65  71  80  85  87  91  95  98  99 100 102 105\n",
      " 106 107 120 121 127 128 130 133 134 135 138 142 156 159 160 161 162 166\n",
      " 169 170 171 178 186 187 189 190 191 200 201 205 206 207 212 213 214 215\n",
      " 216 217 221 224 226 230 236 240 241 242 243 251 252 254 256 259 260 267\n",
      " 269 270 273 276 279 282 283 285 288 292 295 300 303 308 309 313 315 326\n",
      " 327 330 337 339 343 344 345 347 350 351 358 359 366 372 376 378 379 385\n",
      " 387 389 391 392 397 400 401 406 409 412 413 417 418 419 427 429 430 435\n",
      " 445 447 448 454 455 456 458 459 461 466 467 472 474 475 476 478 479 483\n",
      " 484 488 491 492 493 504 505 506 508 509 510 515 516 518 522 524 525 529\n",
      " 534 537 552 554 558 559 560 563 566]\n"
     ]
    }
   ],
   "source": [
    "cnt = 1#カウント用の数字\n",
    "for tr_idx, va_idx in kf.split(train_x):#クロスバリデーションで分割。for：繰り返し(n_splitsの回数繰り返す),in：どんな条件で繰り返すか\n",
    "    print('########{}回目:データ数 tr:{},va:{}########'.format(cnt,len(tr_idx),len(va_idx)))#print:文字列を出力、len([]):リストの長さ\n",
    "    print('tr_idx:{}'.format(tr_idx))#'{}'.format(変数)\n",
    "    print('va_idx:{}'.format(va_idx))\n",
    "    cnt += 1#cntを1足す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初期ハイパーパラメータ初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9526315789473684\n",
      "logloss : 0.16737458759897722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9631578947368421\n",
      "logloss : 0.16552806778699025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9629629629629629\n",
      "logloss : 0.17521848393273715\n",
      "scores_logloss:[0.16737458759897722, 0.16552806778699025, 0.17521848393273715]\n",
      "scores_accuracy:[0.9526315789473684, 0.9631578947368421, 0.9629629629629629]\n",
      "===予測モデルの評価指標(平均スコア)===\n",
      "logloss: 0.1694, accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "for tr_idx, va_idx in kf.split(train_x):#クロスバリデーションで分割。for：繰り返し(n_splitsの回数繰り返す),in：どんな条件で繰り返すか\n",
    "    # 学習データを学習データとバリデーションデータに分ける\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]#iloc[]:行番号、列番号を指定して要素を取り出す\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "    # モデルの学習を行う\n",
    "    model = lgb.LGBMClassifier() # LightGBMのモデルを定義。分類:LGBMClassifier(),回帰:LGBMRegressor()\n",
    "    model.fit(tr_x, tr_y) # モデルの学習:fit(説明変数,目的変数)\n",
    "\n",
    "    # テストデータの予測クラス (予測クラス(0 or 1)を返す)\n",
    "    y_pred = model.predict(va_x)\n",
    "    # テストデータのクラス予測確率 (各クラスの予測確率 [クラス0の予測確率,クラス1の予測確率] を返す)\n",
    "    y_pred_prob = model.predict_proba(va_x)    \n",
    "\n",
    "    # モデル評価\n",
    "    # acc : 正答率\n",
    "    accuracy = accuracy_score(va_y,y_pred)#accuracy_score(正解値,予測値)\n",
    "    print('accuracy :',accuracy)\n",
    "\n",
    "    # 評価関数LogLoss \n",
    "    logloss =  log_loss(va_y,y_pred_prob) # 引数 : log_loss(正解クラス,[クラス0の予測確率,クラス1の予測確率])\n",
    "    print('logloss :', logloss)\n",
    "\n",
    "    # 各foldのスコアを保存する\n",
    "    scores_logloss.append(logloss)#append:listに追加\n",
    "    scores_accuracy.append(accuracy)\n",
    "\n",
    "# 各foldのスコアの平均を出力する\n",
    "print('scores_logloss:{}'.format(scores_logloss))\n",
    "print('scores_accuracy:{}'.format(scores_accuracy))\n",
    "logloss = np.mean(scores_logloss)#各foldの評価関数LogLossの平均値\n",
    "accuracy = np.mean(scores_accuracy)#各foldの正解率の平均値\n",
    "print(\"===予測モデルの評価指標(平均スコア)===\")\n",
    "print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')#f'':変数をそのまま指定できる,{*.4f}:小数点以下の桁数(この場合4桁)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドリサーチでハイパーパラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 375 out of 375 | elapsed:   51.0s finished\n",
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===予測モデルの評価指標(平均スコア)===\n",
      "最も良いパラメータ:{'learning_rate': 0.09, 'max_depth': 5, 'num_leaves': 8}\n",
      "accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV#グリッドサーチのライブラリ\n",
    "\n",
    "model = lgb.LGBMClassifier() # LightGBMのモデルを定義\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)#n_splits:分割,shuffle:シャッフルするかどうか,random_state:何度実行しても同じランダムな分割になるように固定する値。指定しないと毎\n",
    "\n",
    "# パラメーターを設定する\n",
    "param_grid = {\"max_depth\": [5,6,7,8,9],#木構造の深さを限定するための変数．データが少ないときに過学習を防ぐために設定する\n",
    "              \"learning_rate\" : [0.05,0.06,0.07,0.08,0.09],#学習率\n",
    "              'num_leaves': [5,6,7,8,9]#木にある分岐の個数\n",
    "             }\n",
    "# パラメータチューニングをグリッドサーチで行うために設定する\n",
    "## このGridSearchCV には注意が必要 scoring は そのスコアを基準にして最適化する\n",
    "grid = GridSearchCV(estimator = model,#モデル\n",
    "                    param_grid = param_grid,#パラメータ\n",
    "                    scoring = 'accuracy',#評価指標\n",
    "                    cv = kf,#交差検定の回数\n",
    "                    verbose=1,#verbose=1:一定の間隔でログ表示，verbose=2:テスト毎にログ表示，verbose=3:テスト毎にスコアも含めてログ表示\n",
    "                    return_train_score = True,#False場合、トレーニングスコアを含まない\n",
    "                    n_jobs = -1)#同時実行数(-1にするとコア数で同時実行)。#コア数とはコンピュータのCPUに内蔵された稼働するプロセッサコアの数。 コアの数だけ複数のプログラムを並列に動作させられる\n",
    "\n",
    "grid.fit(train_x, train_y)#学習\n",
    "\n",
    "print(\"===予測モデルの評価指標(平均スコア)===\")\n",
    "print(\"最も良いパラメータ:{}\".format(grid.best_params_))\n",
    "print(f'accuracy: {grid.best_score_:.4f}')#f'':変数をそのまま指定できる,{*.4f}:小数点以下の桁数(この場合4桁)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブル学習(https://potesara-tips.com/ensemble-voting/#toc10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb#機械学習モデル：xgboost\n",
    "import lightgbm as lgb#機械学習モデル：lightgbm\n",
    "from catboost import CatBoost#機械学習モデル：catboost\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, X_test, y_test, loop_counts):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    xgb_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    xgb_eval = xgb.DMatrix(X_eval_cv, label=y_eval_cv)\n",
    "    # テスト用\n",
    "    xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    # パラメータを設定\n",
    "    xgb_params = {\n",
    "        'objective': 'multi:softprob',  # 多値分類問題\n",
    "        'num_class': 3,                 # 目的変数のクラス数\n",
    "        'learning_rate': 0.1,           # 学習率\n",
    "        'eval_metric': 'mlogloss'       # 学習用の指標 (Multiclass logloss)\n",
    "    }\n",
    "\n",
    "    # 学習\n",
    "    evals = [(xgb_train, 'train'), (xgb_eval, 'eval')] # 学習に用いる検証用データ\n",
    "    evaluation_results = {}                            # 学習の経過を保存する箱\n",
    "    bst = xgb.train(xgb_params,                        # 上記で設定したパラメータ\n",
    "                    xgb_train,                         # 使用するデータセット\n",
    "                    num_boost_round=200,               # 学習の回数\n",
    "                    early_stopping_rounds=10,          # アーリーストッピング\n",
    "                    evals=evals,                       # 学習経過で表示する名称\n",
    "                    evals_result=evaluation_results,   # 上記で設定した検証用データ\n",
    "                    verbose_eval=0                     # 学習の経過の表示(非表示)\n",
    "                    )\n",
    "    \n",
    "    # テストデータで予測\n",
    "    y_pred = bst.predict(xgb_test, ntree_limit=bst.best_ntree_limit)\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print('Trial: ' + str(loop_counts))\n",
    "    accuracy = accuracy_score(y_test.values.tolist(), y_pred_max)\n",
    "    print('XGBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(bst, y_pred_max, accuracy)#return:出力、bst:モデル、y_pred_max:予測値,acuracy:正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_train(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, X_test, y_test):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    lgb_train = lgb.Dataset(X_train_cv, y_train_cv,\n",
    "                            free_raw_data=False)\n",
    "    # 検証用\n",
    "    lgb_eval = lgb.Dataset(X_eval_cv, y_eval_cv, reference=lgb_train,\n",
    "                           free_raw_data=False)\n",
    "    \n",
    "    # パラメータを設定\n",
    "    params = {'task': 'train',                # レーニング ⇔　予測predict\n",
    "              'boosting_type': 'gbdt',        # 勾配ブースティング\n",
    "              'objective': 'multiclass',      # 目的関数：多値分類、マルチクラス分類\n",
    "              'metric': 'multi_logloss',      # 検証用データセットで、分類モデルの性能を測る指標\n",
    "              'num_class': 3,                 # 目的変数のクラス数\n",
    "              'learning_rate': 0.1,           # 学習率（初期値0.1）\n",
    "              'num_leaves': 23,               # 決定木の複雑度を調整（初期値31）\n",
    "              'min_data_in_leaf': 1,          # データの最小数（初期値20）\n",
    "              'verbose': -1,\n",
    "             }\n",
    "\n",
    "    # 学習\n",
    "    evaluation_results = {}                                # 学習の経過を保存する箱\n",
    "    model = lgb.train(params,                              # 上記で設定したパラメータ\n",
    "                      lgb_train,                           # 使用するデータセット\n",
    "                      num_boost_round=200,                 # 学習の回数\n",
    "                      valid_names=['train', 'valid'],      # 学習経過で表示する名称\n",
    "                      valid_sets=[lgb_train, lgb_eval],    # モデルの検証に使用するデータセット\n",
    "                      evals_result=evaluation_results,     # 学習の経過を保存\n",
    "                      early_stopping_rounds=10,            # アーリーストッピングの回数\n",
    "                      verbose_eval=0)                      # 学習の経過を表示する刻み（非表示）\n",
    "\n",
    "    # テストデータで予測\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "    # Accuracy の計算\n",
    "    accuracy = accuracy_score(y_test, y_pred_max)\n",
    "    #accuracy = sum(y_test == y_pred_max) / len(y_test)\n",
    "    print('LightGBM Accuracy:', accuracy)\n",
    "    \n",
    "    return(model, y_pred_max, accuracy)#return:出力、model:モデル、y_pred_max:予測値,acuracy:正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_train(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, X_test, y_test):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    CatBoost_train = Pool(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    CatBoost_eval = Pool(X_eval_cv, label=y_eval_cv)\n",
    "    \n",
    "    # パラメータを設定\n",
    "    params = {        \n",
    "        'loss_function': 'MultiClass',    # 多値分類問題\n",
    "        'num_boost_round': 1000,          # 学習の回数\n",
    "        'early_stopping_rounds': 10       # アーリーストッピングの回数\n",
    "    }\n",
    "    \n",
    "    # 学習\n",
    "    catb = CatBoost(params)\n",
    "    catb.fit(CatBoost_train, eval_set=[CatBoost_eval], verbose=False)\n",
    "\n",
    "    # テストデータで予測\n",
    "    y_pred = catb.predict(X_test, prediction_type='Probability')\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Accuracy の計算\n",
    "    accuracy = accuracy_score(y_test, y_pred_max)\n",
    "    #accuracy = sum(y_test == y_pred_max) / len(y_test)\n",
    "    print('CatBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(catb, y_pred_max, accuracy)#return:出力、catb:モデル、y_pred_max:予測値,acuracy:正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 1.0\n",
      "Trial: 2\n",
      "XGBoost Accuracy: 1.0\n",
      "LightGBM Accuracy: 0.9722222222222222\n",
      "CatBoost Accuracy: 0.9444444444444444\n",
      "Trial: 3\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 4\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9166666666666666\n",
      "CatBoost Accuracy: 0.9722222222222222\n",
      "Trial: 5\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9722222222222222\n",
      "CatBoost Accuracy: 0.9444444444444444\n",
      "Trial: 6\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9166666666666666\n",
      "CatBoost Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 7\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 0.9722222222222222\n",
      "Trial: 8\n",
      "XGBoost Accuracy: 0.9166666666666666\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 0.9444444444444444\n",
      "Trial: 9\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9722222222222222\n",
      "CatBoost Accuracy: 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 10\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.8888888888888888\n",
      "CatBoost Accuracy: 1.0\n",
      "Trial: 11\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9722222222222222\n",
      "CatBoost Accuracy: 0.9722222222222222\n",
      "Trial: 12\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 13\n",
      "XGBoost Accuracy: 0.9722222222222222\n",
      "LightGBM Accuracy: 0.9722222222222222\n",
      "CatBoost Accuracy: 1.0\n",
      "Trial: 14\n",
      "XGBoost Accuracy: 0.9444444444444444\n",
      "LightGBM Accuracy: 0.8888888888888888\n",
      "CatBoost Accuracy: 0.9722222222222222\n",
      "Trial: 15\n",
      "XGBoost Accuracy: 1.0\n",
      "LightGBM Accuracy: 0.9444444444444444\n",
      "CatBoost Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb#機械学習モデル：xgboost\n",
    "import lightgbm as lgb#機械学習モデル：lightgbm\n",
    "from catboost import CatBoost#機械学習モデル：catboost\n",
    "from catboost import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Voting\n",
    "# 各5つのモデルを保存するリストの初期化\n",
    "xgb_models = []\n",
    "lgbm_models = []\n",
    "catb_models = []\n",
    "# 各5つのモデルの正答率を保存するリストの初期化\n",
    "xgb_accuracies = []\n",
    "lgbm_accuracies = []\n",
    "catb_accuracies = []\n",
    "# 学習のカウンター\n",
    "loop_counts = 1\n",
    "\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=train_y)\n",
    "\n",
    "# 各5つのモデルの予測を保存する配列の初期化（5seed*5cv*3モデル）\n",
    "first_preds = np.zeros((len(y_test), 5*3*3))\n",
    "\n",
    "\n",
    "# ５つのシード値で予測\n",
    "for seed_no in range(5): \n",
    "        \n",
    "    # 学習データの数だけの数列（0行から最終行まで連番）\n",
    "    row_no_list = list(range(len(y_train)))\n",
    "\n",
    "    # KFoldクラスをインスタンス化（これを使って3分割する）\n",
    "    K_fold = StratifiedKFold(n_splits=3, shuffle=True,  random_state= seed_no)\n",
    "\n",
    "    # KFoldクラスで分割した回数だけ実行（ここでは5回）\n",
    "    for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n",
    "        # ilocで取り出す行を指定\n",
    "        X_train_cv = X_train.iloc[train_cv_no, :]\n",
    "        #y_train_cv = pd.Series(y_train).iloc[train_cv_no]\n",
    "        y_train_cv = y_train.iloc[train_cv_no]\n",
    "        X_eval_cv = X_train.iloc[eval_cv_no, :]\n",
    "        #y_eval_cv = pd.Series(y_train).iloc[eval_cv_no]\n",
    "        y_eval_cv = y_train.iloc[eval_cv_no]\n",
    "        \n",
    "        # XGBoostの学習を実行\n",
    "        bst, bst_pred, bst_accuracy = xgb_train(X_train_cv, y_train_cv,\n",
    "                                                X_eval_cv, y_eval_cv, \n",
    "                                                X_test, y_test,\n",
    "                                                loop_counts)\n",
    "        # LIghtGBMの学習を実行\n",
    "        model, model_pred, model_accuracy = lgbm_train(X_train_cv, y_train_cv,\n",
    "                                                       X_eval_cv, y_eval_cv,\n",
    "                                                       X_test, y_test)\n",
    "        # CatBoostの学習を実行\n",
    "        catb, catb_pred, catb_accuracy = catboost_train(X_train_cv, y_train_cv,\n",
    "                                                        X_eval_cv, y_eval_cv,\n",
    "                                                        X_test, y_test)\n",
    "        \n",
    "        # 学習が終わったモデルをリストに入れておく\n",
    "        xgb_models.append(bst) \n",
    "        lgbm_models.append(model) \n",
    "        catb_models.append(catb) \n",
    "               \n",
    "        # 学習が終わったモデルの正答率をリストに入れておく\n",
    "        xgb_accuracies.append(bst_accuracy) \n",
    "        lgbm_accuracies.append(model_accuracy) \n",
    "        catb_accuracies.append(catb_accuracy) \n",
    "               \n",
    "        # 学習が終わったモデルの予測をリストに入れておく\n",
    "        first_preds[:, loop_counts-1] = bst_pred\n",
    "        first_preds[:, loop_counts-1 + 15] = model_pred\n",
    "        first_preds[:, loop_counts-1 + 30] = catb_pred\n",
    "        \n",
    "        # 実行回数のカウント\n",
    "        loop_counts += 1        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s180168\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1\n",
      "XGBoost Accuracy: 0.9736842105263158\n",
      "LightGBM Accuracy: 0.9649122807017544\n",
      "CatBoost Accuracy: 0.9736842105263158\n",
      "Trial: 2\n",
      "XGBoost Accuracy: 0.9824561403508771\n",
      "LightGBM Accuracy: 0.9385964912280702\n",
      "CatBoost Accuracy: 0.956140350877193\n",
      "Trial: 3\n",
      "XGBoost Accuracy: 0.956140350877193\n",
      "LightGBM Accuracy: 0.956140350877193\n",
      "CatBoost Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb#機械学習モデル：xgboost\n",
    "import lightgbm as lgb#機械学習モデル：lightgbm\n",
    "from catboost import CatBoost#機械学習モデル：catboost\n",
    "from catboost import Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Voting\n",
    "# 各5つのモデルを保存するリストの初期化\n",
    "xgb_models = []\n",
    "lgbm_models = []\n",
    "catb_models = []\n",
    "# 各5つのモデルの正答率を保存するリストの初期化\n",
    "xgb_accuracies = []\n",
    "lgbm_accuracies = []\n",
    "catb_accuracies = []\n",
    "# 学習のカウンター\n",
    "loop_counts = 1\n",
    "\n",
    "\n",
    "# 各5つのモデルの予測を保存する配列の初期化（3cv*3モデル）\n",
    "first_preds = np.zeros((len(y_test), 3*3))\n",
    "\n",
    "# 学習データの数だけの数列（0行から最終行まで連番）\n",
    "row_no_list = list(range(len(y_train)))\n",
    "\n",
    "# KFoldクラスをインスタンス化（これを使って3分割する）\n",
    "K_fold = StratifiedKFold(n_splits=3, shuffle=True,  random_state= 1)\n",
    "\n",
    "# KFoldクラスで分割した回数だけ実行（ここでは5回）\n",
    "for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n",
    "    # ilocで取り出す行を指定\n",
    "    X_train_cv = X_train.iloc[train_cv_no, :]\n",
    "    #y_train_cv = pd.Series(y_train).iloc[train_cv_no]\n",
    "    y_train_cv = y_train.iloc[train_cv_no]\n",
    "    X_eval_cv = X_train.iloc[eval_cv_no, :]\n",
    "    #y_eval_cv = pd.Series(y_train).iloc[eval_cv_no]\n",
    "    y_eval_cv = y_train.iloc[eval_cv_no]\n",
    "\n",
    "    # XGBoostの学習を実行\n",
    "    bst, bst_pred, bst_accuracy = xgb_train(X_train_cv, y_train_cv,\n",
    "                                            X_eval_cv, y_eval_cv, \n",
    "                                            X_test, y_test,\n",
    "                                            loop_counts)\n",
    "    # LIghtGBMの学習を実行\n",
    "    model, model_pred, model_accuracy = lgbm_train(X_train_cv, y_train_cv,\n",
    "                                                   X_eval_cv, y_eval_cv,\n",
    "                                                   X_test, y_test)\n",
    "    # CatBoostの学習を実行\n",
    "    catb, catb_pred, catb_accuracy = catboost_train(X_train_cv, y_train_cv,\n",
    "                                                    X_eval_cv, y_eval_cv,\n",
    "                                                    X_test, y_test)\n",
    "\n",
    "    # 学習が終わったモデルをリストに入れておく\n",
    "    xgb_models.append(bst) \n",
    "    lgbm_models.append(model) \n",
    "    catb_models.append(catb) \n",
    "\n",
    "    # 学習が終わったモデルの正答率をリストに入れておく\n",
    "    xgb_accuracies.append(bst_accuracy) \n",
    "    lgbm_accuracies.append(model_accuracy) \n",
    "    catb_accuracies.append(catb_accuracy) \n",
    "\n",
    "    # 学習が終わったモデルの予測をリストに入れておく\n",
    "    first_preds[:, loop_counts-1] = bst_pred\n",
    "    first_preds[:, loop_counts-1 + 3] = model_pred\n",
    "    first_preds[:, loop_counts-1 + 6] = catb_pred\n",
    "\n",
    "    # 実行回数のカウント\n",
    "    loop_counts += 1        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy:  0.9707602339181287\n",
      "LightGBM Accuracy:  0.9532163742690059\n",
      "CatBoost Accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 単独のモデルでの、テストデータの正答率\n",
    "print('XGBoost Accuracy: ', np.array(xgb_accuracies).mean())#平均値算出\n",
    "print('LightGBM Accuracy: ', np.array(lgbm_accuracies).mean())#平均値算出\n",
    "print('CatBoost Accuracy: ', np.array(catb_accuracies).mean())#平均値算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# アンサンブルのモデルでの、テストデータの正答率\n",
    "import itertools\n",
    "# データ格納用のnumpy行列を作成\n",
    "first_preds_max = pd.DataFrame(np.zeros((len(y_test), 3)))\n",
    "\n",
    "# 予測したクラスのデータをpandas.DataFrameに入れる\n",
    "df_first_preds = pd.DataFrame(first_preds)\n",
    "\n",
    "# 各列（0,1,2）に、そのクラスを予測したモデルの数を入れる\n",
    "first_preds_max.iloc[:, 0] = (df_first_preds == 0).sum(axis=1)\n",
    "first_preds_max.iloc[:, 1] = (df_first_preds == 1).sum(axis=1)\n",
    "first_preds_max.iloc[:, 2] = (df_first_preds == 2).sum(axis=1)\n",
    "\n",
    "# 各行で、そのクラスを予測したモデルの数が最も多いクラスを得る\n",
    "pred_max = np.argmax(np.array(first_preds_max), axis=1)\n",
    "\n",
    "# Accuracy を計算する\n",
    "#accuracy = sum(y_test.values.tolist() == pred_max) / len(y_test)\n",
    "accuracy = accuracy_score(y_test, pred_max)\n",
    "print('accuracy:', accuracy)\n",
    "#df_accuracy = pd.DataFrame({'va_y': list(itertools.chain.from_iterable(y_test.values)),\n",
    "#                            'y_pred_max': pred_max})\n",
    "#print(pd.crosstab(df_accuracy['va_y'], df_accuracy['y_pred_max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
